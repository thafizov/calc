#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º –¶–ë –†–§
–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
1. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: https://www.cbr.ru/statistics/bank_sector/int_rat/
2. –ê—Ä—Ö–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: https://www.cbr.ru/statistics/b_sector/interest_rates_00/ (2000-2012)
3. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –±—é–ª–ª–µ—Ç–µ–Ω–∏: https://www.cbr.ru/statistics/bbs/ (2013-2019)
"""

import requests
import json
from datetime import datetime, timedelta
import pandas as pd
import time
import re
from bs4 import BeautifulSoup

class CBRDepositsParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.base_url = 'https://www.cbr.ru'
        self.deposits_data = {}
        
    def parse_bulletin_data(self, start_year=2013, end_year=2019):
        """
        –ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π –¶–ë –†–§ –∑–∞ 2013-2019 –≥–æ–¥—ã
        """
        print(f"üì∞ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π –¶–ë ({start_year}-{end_year})...")
        
        # URL –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π
        bulletin_url = f"{self.base_url}/statistics/bbs/"
        
        for year in range(start_year, end_year + 1):
            print(f"  ‚îî‚îÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {year} –≥–æ–¥...")
            
            for month in range(1, 13):
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—é–ª–ª–µ—Ç–µ–Ω—è
                # –ü—Ä–∏–º–µ—Ä: https://www.cbr.ru/statistics/bbs/2013/12/
                month_url = f"{bulletin_url}{year}/{month:02d}/"
                
                try:
                    response = self.session.get(month_url, timeout=10)
                    if response.status_code == 200:
                        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ Excel/PDF —Ñ–∞–π–ª—ã —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
                        data = self._parse_bulletin_page(response.text, year, month)
                        if data:
                            key = f"{year}-{month:02d}"
                            self.deposits_data[key] = data
                            print(f"    ‚úÖ {year}-{month:02d}")
                    else:
                        print(f"    ‚ö†Ô∏è  {year}-{month:02d}: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                        
                    time.sleep(0.5)  # –í–µ–∂–ª–∏–≤–∞—è –ø–∞—É–∑–∞
                    
                except Exception as e:
                    print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –¥–ª—è {year}-{month:02d}: {e}")
                    continue
                    
    def _parse_bulletin_page(self, html_content, year, month):
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—é–ª–ª–µ—Ç–µ–Ω—è
        –ò—â–µ—Ç Excel —Ñ–∞–π–ª—ã —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ñ–∞–π–ª—ã —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
        links = soup.find_all('a', href=True)
        
        for link in links:
            href = link.get('href', '')
            text = link.get_text().lower()
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–µ —Å—Ç–∞–≤–∫–∏
            if any(keyword in text for keyword in ['–¥–µ–ø–æ–∑–∏—Ç', '–≤–∫–ª–∞–¥', '–ø—Ä–æ—Ü–µ–Ω—Ç', '—Å—Ç–∞–≤–∫']):
                if any(ext in href for ext in ['.xls', '.xlsx', '.zip']):
                    # –ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å –∏ –ø–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª
                    return self._download_and_parse_bulletin_file(href, year, month)
                    
        # –ï—Å–ª–∏ –ø—Ä—è–º—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        return self._extract_rates_from_bulletin_html(soup, year, month)
        
    def _download_and_parse_bulletin_file(self, file_url, year, month):
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –ø–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
        """
        try:
            if not file_url.startswith('http'):
                file_url = self.base_url + file_url
                
            response = self.session.get(file_url, timeout=15)
            if response.status_code == 200:
                # –ï—Å–ª–∏ —ç—Ç–æ Excel —Ñ–∞–π–ª
                if file_url.endswith(('.xls', '.xlsx')):
                    return self._parse_excel_bulletin(response.content, year, month)
                    
        except Exception as e:
            print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            
        return None
        
    def _parse_excel_bulletin(self, excel_content, year, month):
        """
        –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—é–ª–ª–µ—Ç–µ–Ω—è
        """
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã Excel —Ñ–∞–π–ª–∞
            df_dict = pd.read_excel(excel_content, sheet_name=None)
            
            for sheet_name, df in df_dict.items():
                if any(keyword in sheet_name.lower() for keyword in ['–¥–µ–ø–æ–∑–∏—Ç', '–≤–∫–ª–∞–¥', '—Å—Ç–∞–≤–∫']):
                    # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º
                    rates = self._extract_rates_from_dataframe(df, year, month)
                    if rates:
                        return rates
                        
        except Exception as e:
            print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel: {e}")
            
        return None
        
    def _extract_rates_from_dataframe(self, df, year, month):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–µ —Å—Ç–∞–≤–∫–∏ –∏–∑ DataFrame
        """
        try:
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
            for index, row in df.iterrows():
                for col in df.columns:
                    cell_value = str(row[col]).lower()
                    
                    if any(keyword in cell_value for keyword in ['–¥–µ–ø–æ–∑–∏—Ç', '–≤–∫–ª–∞–¥ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü']):
                        # –ò—â–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–µ
                        rates = []
                        for next_col in df.columns[list(df.columns).index(col)+1:]:
                            try:
                                rate_val = float(row[next_col])
                                if 0.001 < rate_val < 1:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç–∞–≤–æ–∫
                                    rates.append(rate_val)
                            except (ValueError, TypeError):
                                continue
                                
                        if len(rates) >= 1:
                            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å—Ç–∞–≤–∫–∏, —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
                            base_rate = rates[0]
                            return {
                                "<1": base_rate,
                                "1-3": rates[1] if len(rates) > 1 else base_rate * 1.1,
                                ">3": rates[2] if len(rates) > 2 else base_rate * 1.2
                            }
                            
        except Exception as e:
            print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ DataFrame: {e}")
            
        return None
        
    def _extract_rates_from_bulletin_html(self, soup, year, month):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞–≤–∫–∏ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±—é–ª–ª–µ—Ç–µ–Ω—è
        """
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    text = cells[0].get_text().strip().lower()
                    
                    if any(keyword in text for keyword in ['–¥–µ–ø–æ–∑–∏—Ç', '–≤–∫–ª–∞–¥ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü']):
                        # –ò—â–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —è—á–µ–π–∫–∞—Ö
                        rates = []
                        for cell in cells[1:]:
                            try:
                                rate_text = cell.get_text().strip()
                                rate_val = float(rate_text.replace(',', '.').replace('%', ''))
                                
                                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ –¥–æ–ª–∏
                                if rate_val > 1:
                                    rate_val = rate_val / 100
                                    
                                if 0.001 < rate_val < 1:
                                    rates.append(rate_val)
                                    
                            except (ValueError, TypeError):
                                continue
                                
                        if len(rates) >= 1:
                            base_rate = rates[0]
                            return {
                                "<1": base_rate,
                                "1-3": rates[1] if len(rates) > 1 else base_rate * 1.1,
                                ">3": rates[2] if len(rates) > 2 else base_rate * 1.2
                            }
                            
        return None
        
    def parse_modern_data(self, start_year=2020, end_year=2025):
        """
        –ü–∞—Ä—Å–∏—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ –¶–ë –†–§
        –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ —Å—Ç–∞–≤–∫–∏ –ø–æ –≤–∫–ª–∞–¥–∞–º —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü
        """
        print(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¶–ë ({start_year}-{end_year})...")
        
        # URL –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        url = f"{self.base_url}/statistics/bank_sector/int_rat/"
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ–¥–∞ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        for year in range(start_year, end_year + 1):
            print(f"  ‚îî‚îÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {year} –≥–æ–¥...")
            
            for month in range(1, 13):
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º–µ—Å—è—Ü–∞
                month_url = f"{url}{year:04d}{month:02d}/"
                
                try:
                    response = self.session.get(month_url, timeout=10)
                    if response.status_code == 200:
                        # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –ø–∞—Ä—Å–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É
                        data = self._parse_monthly_page(response.text, year, month)
                        if data:
                            key = f"{year}-{month:02d}"
                            self.deposits_data[key] = data
                            
                    time.sleep(1)  # –í–µ–∂–ª–∏–≤–∞—è –ø–∞—É–∑–∞
                    
                except Exception as e:
                    print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –¥–ª—è {year}-{month:02d}: {e}")
                    continue
                    
    def parse_archive_data(self, start_year=2000, end_year=2012):
        """
        –ü–∞—Ä—Å–∏—Ç –∞—Ä—Ö–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ 2000-2012 –≥–æ–¥—ã
        """
        print(f"üìö –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä—Ö–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¶–ë ({start_year}-{end_year})...")
        
        # –ê—Ä—Ö–∏–≤–Ω—ã–µ URL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ª–µ—Ç
        for year in range(start_year, end_year + 1):
            url = f"{self.base_url}/statistics/b_sector/interest_rates_{year-2000:02d}/"
            
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    data = self._parse_archive_year(response.text, year)
                    if data:
                        self.deposits_data.update(data)
                        print(f"  ‚úÖ {year} –≥–æ–¥ - –ø–æ–ª—É—á–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π")
                        
                time.sleep(1)
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –¥–ª—è {year}: {e}")
                continue
                
    def _parse_monthly_page(self, html_content, year, month):
        """
        –ü–∞—Ä—Å–∏—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –¥–∞–Ω–Ω—ã–º–∏ –∑–∞ –º–µ—Å—è—Ü
        –ò—â–µ—Ç —Ç–∞–±–ª–∏—Ü—ã —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏
        tables = soup.find_all('table')
        
        for table in tables:
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –≤–∫–ª–∞–¥–∞–º–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü
            headers = table.find_all('th')
            if any('–≤–∫–ª–∞–¥' in th.get_text().lower() for th in headers):
                return self._extract_deposit_rates(table, year, month)
                
        return None
        
    def _parse_archive_year(self, html_content, year):
        """
        –ü–∞—Ä—Å–∏—Ç –∞—Ä—Ö–∏–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –¥–∞–Ω–Ω—ã–º–∏ –∑–∞ –≥–æ–¥
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        year_data = {}
        
        # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã —Å –º–µ—Å—è—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 13:  # 12 –º–µ—Å—è—Ü–µ–≤ + –Ω–∞–∑–≤–∞–Ω–∏–µ
                    text = cells[0].get_text().strip().lower()
                    
                    if '–¥–µ–ø–æ–∑–∏—Ç' in text or '–≤–∫–ª–∞–¥' in text:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–µ—Å—è—Ü–∞–º
                        for month in range(1, 13):
                            try:
                                if month < len(cells):
                                    rate_text = cells[month].get_text().strip()
                                    if rate_text and rate_text != '‚Äî':
                                        rate = float(rate_text.replace(',', '.')) / 100
                                        key = f"{year}-{month:02d}"
                                        
                                        # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω—É —Å—Ç–∞–≤–∫—É –¥–ª—è –≤—Å–µ—Ö —Å—Ä–æ–∫–æ–≤
                                        year_data[key] = {
                                            "<1": rate,
                                            "1-3": rate * 1.1,  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ +10% –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö
                                            ">3": rate * 1.2    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ +20% –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö
                                        }
                            except (ValueError, IndexError):
                                continue
                                
        return year_data
        
    def _extract_deposit_rates(self, table, year, month):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞–≤–∫–∏ –ø–æ –¥–µ–ø–æ–∑–∏—Ç–∞–º –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
        """
        rows = table.find_all('tr')
        
        # –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫ —Å –¥–µ–ø–æ–∑–∏—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏ –ø–æ —Å—Ä–æ–∫–∞–º
        short_term = None  # –¥–æ 1 –≥–æ–¥–∞
        medium_term = None  # 1-3 –≥–æ–¥–∞  
        long_term = None   # —Å–≤—ã—à–µ 3 –ª–µ—Ç
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 2:
                text = cells[0].get_text().strip().lower()
                
                try:
                    rate_text = cells[1].get_text().strip()
                    if rate_text and rate_text != '‚Äî':
                        rate = float(rate_text.replace(',', '.').replace('%', '')) / 100
                        
                        if '–¥–æ 1' in text or '<1' in text:
                            short_term = rate
                        elif '1-3' in text or '1 –¥–æ 3' in text:
                            medium_term = rate
                        elif '>3' in text or '—Å–≤—ã—à–µ 3' in text:
                            long_term = rate
                            
                except (ValueError, IndexError):
                    continue
                    
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–∞–Ω–Ω—ã–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
        if any([short_term, medium_term, long_term]):
            return {
                "<1": short_term or 0.05,     # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                "1-3": medium_term or 0.06,   # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                ">3": long_term or 0.07       # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            }
            
        return None
        
    def get_cbr_api_data(self):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API –¶–ë (–µ—Å–ª–∏ –µ—Å—Ç—å)
        """
        print("üîó –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API –¶–ë...")
        
        # API endpoint –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        api_url = "https://www.cbr.ru/Queries/UniDbQuery/DownloadExcel"
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –¥–µ–ø–æ–∑–∏—Ç–Ω—ã—Ö —Å—Ç–∞–≤–æ–∫
        params = {
            'Posted': 'True',
            'so': 'MonthArch',
            'VAL_NM_RQ': 'R01',  # –†—É–±–ª–∏
            'From': '01.01.2000',
            'To': datetime.now().strftime('%d.%m.%Y')
        }
        
        try:
            response = self.session.get(api_url, params=params, timeout=30)
            if response.status_code == 200:
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ Excel —Ñ–∞–π–ª, –ø–∞—Ä—Å–∏–º –µ–≥–æ
                return self._parse_excel_data(response.content)
        except Exception as e:
            print(f"  ‚ö†Ô∏è  API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            
        return None
        
    def _parse_excel_data(self, excel_content):
        """
        –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¶–ë
        """
        try:
            df = pd.read_excel(excel_content)
            # –õ–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel —Ñ–∞–π–ª–∞
            # –≠—Ç–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞ –¶–ë
            return {}
        except Exception as e:
            print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel: {e}")
            return None
            
    def save_to_json(self, filename='data/deposits_real.json'):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª
        """
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ {filename}...")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–∞–º
        sorted_data = dict(sorted(self.deposits_data.items()))
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(sorted_data, f, ensure_ascii=False, indent=2)
            
        print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(sorted_data)} –∑–∞–ø–∏—Å–µ–π")
        return len(sorted_data)
        
    def validate_data(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        issues = []
        
        for date, rates in self.deposits_data.items():
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if not isinstance(rates, dict):
                issues.append(f"{date}: –Ω–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
                continue
                
            required_keys = ["<1", "1-3", ">3"]
            for key in required_keys:
                if key not in rates:
                    issues.append(f"{date}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {key}")
                    
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π
            if rates.get("<1", 0) > 1:  # –°—Ç–∞–≤–∫–∞ –±–æ–ª—å—à–µ 100%
                issues.append(f"{date}: –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∞—è —Å—Ç–∞–≤–∫–∞ <1 –≥–æ–¥–∞: {rates['<1']}")
                
        if issues:
            print(f"  ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(issues)} –ø—Ä–æ–±–ª–µ–º:")
            for issue in issues[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"    - {issue}")
        else:
            print("  ‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é")
            
        return len(issues) == 0

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    """
    print("üè¶ –ü–∞—Ä—Å–µ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–µ–ø–æ–∑–∏—Ç–Ω—ã—Ö —Å—Ç–∞–≤–æ–∫ –¶–ë –†–§")
    print("=" * 50)
    
    parser = CBRDepositsParser()
    
    try:
        # 1. –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API
        api_data = parser.get_cbr_api_data()
        if api_data:
            parser.deposits_data.update(api_data)
            
        # 2. –ü–∞—Ä—Å–∏–º –∞—Ä—Ö–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (2000-2012)
        parser.parse_archive_data(2000, 2012)
        
        # 3. –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –±—é–ª–ª–µ—Ç–µ–Ω–µ–π (2013-2019)
        parser.parse_bulletin_data(2013, 2019)
        
        # 4. –ü–∞—Ä—Å–∏–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (2020-2025)
        parser.parse_modern_data(2020, 2025)
        
        # 5. –í–∞–ª–∏–¥–∞—Ü–∏—è
        parser.validate_data()
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        if parser.deposits_data:
            count = parser.save_to_json()
            print(f"\nüéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω! –ü–æ–ª—É—á–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 